{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "        .master(\"local[1]\") \\\n",
    "        .appName(\"test\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-LCV2U9I:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x209fcc6a150>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(\"Alice\", 25), (\"Bob\", 30), (\"Charlie\", 35)]\n",
    "columns =[\"firstname\",\"age\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+\n",
      "|firstname|age|\n",
      "+---------+---+\n",
      "|    Alice| 25|\n",
      "|      Bob| 30|\n",
      "|  Charlie| 35|\n",
      "+---------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(data =data,schema =columns)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- firstname: string (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+\n",
      "|firstname|age|\n",
      "+---------+---+\n",
      "|      Bob| 30|\n",
      "|  Charlie| 35|\n",
      "+---------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(\"age>=26\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+\n",
      "|firstname|age|\n",
      "+---------+---+\n",
      "|    Alice| 25|\n",
      "|      Bob| 30|\n",
      "|  Charlie| 35|\n",
      "+---------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"firstname\",\"age\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+------------+------------+-------+---------+------+----------+----------+----------+-----------+------------+----+------+\n",
      "|_c0|      Date|AveragePrice|Total Volume|   4046|     4225|  4770|Total Bags|Small Bags|Large Bags|XLarge Bags|        type|year|region|\n",
      "+---+----------+------------+------------+-------+---------+------+----------+----------+----------+-----------+------------+----+------+\n",
      "|  0|2015-12-27|        1.33|    64236.62|1036.74| 54454.85| 48.16|   8696.87|   8603.62|     93.25|        0.0|conventional|2015|Albany|\n",
      "|  1|2015-12-20|        1.35|    54876.98| 674.28| 44638.81| 58.33|   9505.56|   9408.07|     97.49|        0.0|conventional|2015|Albany|\n",
      "|  2|2015-12-13|        0.93|   118220.22|  794.7|109149.67| 130.5|   8145.35|   8042.21|    103.14|        0.0|conventional|2015|Albany|\n",
      "|  3|2015-12-06|        1.08|    78992.15| 1132.0| 71976.41| 72.58|   5811.16|    5677.4|    133.76|        0.0|conventional|2015|Albany|\n",
      "|  4|2015-11-29|        1.28|     51039.6| 941.48| 43838.39| 75.78|   6183.95|   5986.26|    197.69|        0.0|conventional|2015|Albany|\n",
      "|  5|2015-11-22|        1.26|    55979.78|1184.27| 48067.99| 43.61|   6683.91|   6556.47|    127.44|        0.0|conventional|2015|Albany|\n",
      "|  6|2015-11-15|        0.99|    83453.76|1368.92| 73672.72| 93.26|   8318.86|   8196.81|    122.05|        0.0|conventional|2015|Albany|\n",
      "|  7|2015-11-08|        0.98|   109428.33| 703.75|101815.36|  80.0|   6829.22|   6266.85|    562.37|        0.0|conventional|2015|Albany|\n",
      "|  8|2015-11-01|        1.02|    99811.42|1022.15| 87315.57| 85.34|  11388.36|  11104.53|    283.83|        0.0|conventional|2015|Albany|\n",
      "|  9|2015-10-25|        1.07|    74338.76|  842.4| 64757.44| 113.0|   8625.92|   8061.47|    564.45|        0.0|conventional|2015|Albany|\n",
      "| 10|2015-10-18|        1.12|    84843.44| 924.86| 75595.85|117.07|   8205.66|   7877.86|     327.8|        0.0|conventional|2015|Albany|\n",
      "| 11|2015-10-11|        1.28|    64489.17|1582.03| 52677.92|105.32|   10123.9|   9866.27|    257.63|        0.0|conventional|2015|Albany|\n",
      "| 12|2015-10-04|        1.31|     61007.1|2268.32| 49880.67|101.36|   8756.75|   8379.98|    376.77|        0.0|conventional|2015|Albany|\n",
      "| 13|2015-09-27|        0.99|   106803.39|1204.88| 99409.21|154.84|   6034.46|   5888.87|    145.59|        0.0|conventional|2015|Albany|\n",
      "| 14|2015-09-20|        1.33|    69759.01|1028.03| 59313.12| 150.5|   9267.36|    8489.1|    778.26|        0.0|conventional|2015|Albany|\n",
      "| 15|2015-09-13|        1.28|    76111.27| 985.73| 65696.86| 142.0|   9286.68|   8665.19|    621.49|        0.0|conventional|2015|Albany|\n",
      "| 16|2015-09-06|        1.11|    99172.96| 879.45| 90062.62|240.79|    7990.1|   7762.87|    227.23|        0.0|conventional|2015|Albany|\n",
      "| 17|2015-08-30|        1.07|   105693.84| 689.01| 94362.67|335.43|  10306.73|  10218.93|      87.8|        0.0|conventional|2015|Albany|\n",
      "| 18|2015-08-23|        1.34|    79992.09| 733.16| 67933.79|444.78|  10880.36|  10745.79|    134.57|        0.0|conventional|2015|Albany|\n",
      "| 19|2015-08-16|        1.33|    80043.78| 539.65| 68666.01| 394.9|  10443.22|  10297.68|    145.54|        0.0|conventional|2015|Albany|\n",
      "+---+----------+------------+------------+-------+---------+------+----------+----------+----------+-----------+------------+----+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: string, Date: string, AveragePrice: string, Total Volume: string, 4046: string, 4225: string, 4770: string, Total Bags: string, Small Bags: string, Large Bags: string, XLarge Bags: string, type: string, year: string, region: string]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import mean as mean_, std as std_\n",
    "\n",
    "df = spark.read.csv(\"avocado.csv\",header=True)\n",
    "df2 =spark.read.csv(\"avocado.csv\", header= True)\n",
    "df.show()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4059784097758825\n",
      "0.4026765554955525\n",
      "+-------+------------------+----------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------+------------------+----------------+\n",
      "|summary|               _c0|      Date|      AveragePrice|      Total Volume|              4046|              4225|              4770|        Total Bags|        Small Bags|        Large Bags|       XLarge Bags|        type|              year|          region|\n",
      "+-------+------------------+----------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------+------------------+----------------+\n",
      "|  count|             18249|     18249|             18249|             18249|             18249|             18249|             18249|             18249|             18249|             18249|             18249|       18249|             18249|           18249|\n",
      "|   mean|24.232231903117977|      NULL|1.4059784097758825| 850644.0130089332|293008.42453066056|295154.56835607596|22839.735992657315|239639.20205983953|182194.68669571026| 54338.08814455636|3106.4265072058793|        NULL|2016.1478985149872|            NULL|\n",
      "| stddev| 15.48104475375712|      NULL|0.4026765554955525|3453545.3553994684|1264989.0817627835|1204120.4011350533|107464.06843537069| 986242.3992164108| 746178.5149617895|243965.96454740898| 17692.89465191642|        NULL|0.9399384671420276|            NULL|\n",
      "|    min|                 0|2015-01-04|              0.44|           1000.86|               0.0|               0.0|               0.0|               0.0|               0.0|               0.0|               0.0|conventional|              2015|          Albany|\n",
      "|    max|                 9|2018-03-25|              3.25|          99982.71|         999948.52|         999958.67|          99997.75|          99993.25|           9999.53|          999727.7|           9970.21|     organic|              2018|WestTexNewMexico|\n",
      "+-------+------------------+----------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------+------------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import mean as mean_, std as std_ , col\n",
    "\n",
    "df_stats = df.select(\n",
    "    mean_(col('AveragePrice')).alias('mean'),\n",
    "    std_(col('AveragePrice')).alias('std')\n",
    ").collect()\n",
    "\n",
    "avg = df_stats[0]['mean']\n",
    "std = df_stats[0]['std']\n",
    "print(avg)\n",
    "print(std)\n",
    "\n",
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|4046|count|\n",
      "+----+-----+\n",
      "| 0.0|  242|\n",
      "| 3.0|   10|\n",
      "| 1.0|    8|\n",
      "| 4.0|    8|\n",
      "|1.24|    8|\n",
      "+----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('4046').count().orderBy('count', ascending=False).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44\n",
      "1.37\n",
      "3.25\n",
      "+------------+----+----+\n",
      "|        type| %25| %75|\n",
      "+------------+----+----+\n",
      "|     organic|1.42|1.87|\n",
      "|conventional|0.98|1.32|\n",
      "+------------+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import min as minimum_, median as median_ , max as maximum_, col\n",
    "import pyspark.sql.functions as F\n",
    "df_stats = df.select(\n",
    "    minimum_(col('AveragePrice')).alias('min'),\n",
    "    median_(col('AveragePrice')).alias('median'),\n",
    "    maximum_(col('AveragePrice')).alias('max')\n",
    ").collect()\n",
    "\n",
    "min = df_stats[0]['min']\n",
    "median = df_stats[0]['median']\n",
    "max = df_stats[0]['max'] \n",
    "print(min)\n",
    "print(median)\n",
    "print(max)\n",
    "\n",
    "df1 = df.groupby('type').agg(F.expr('percentile(AveragePrice, array(0.25))')[0].alias('%25'),\n",
    "                             F.expr('percentile(AveragePrice, array(0.75))')[0].alias('%75'))\n",
    "\n",
    "df1.show()\n",
    "# df.join(df1, on='', how='left').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- Date: string (nullable = true)\n",
      " |-- AveragePrice: string (nullable = true)\n",
      " |-- Total Volume: string (nullable = true)\n",
      " |-- 4046: string (nullable = true)\n",
      " |-- 4225: string (nullable = true)\n",
      " |-- 4770: string (nullable = true)\n",
      " |-- Total Bags: string (nullable = true)\n",
      " |-- Small Bags: string (nullable = true)\n",
      " |-- Large Bags: string (nullable = true)\n",
      " |-- XLarge Bags: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- year: string (nullable = true)\n",
      " |-- region: string (nullable = true)\n",
      "\n",
      "+--------+\n",
      "|avgprice|\n",
      "+--------+\n",
      "|    1.33|\n",
      "|    1.35|\n",
      "|    0.93|\n",
      "|    1.08|\n",
      "|    1.28|\n",
      "|    1.26|\n",
      "|    0.99|\n",
      "|    0.98|\n",
      "|    1.02|\n",
      "|    1.07|\n",
      "|    1.12|\n",
      "|    1.28|\n",
      "|    1.31|\n",
      "|    0.99|\n",
      "|    1.33|\n",
      "|    1.28|\n",
      "|    1.11|\n",
      "|    1.07|\n",
      "|    1.34|\n",
      "|    1.33|\n",
      "+--------+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- avgprice: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[avgprice: string]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df2.show()\n",
    "\n",
    "df2.printSchema()\n",
    "df2= df2.selectExpr(\"AveragePrice as avgprice\")\n",
    "df2.show()\n",
    "df2.printSchema()\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+\n",
      "|region             |count|\n",
      "+-------------------+-----+\n",
      "|PhoenixTucson      |338  |\n",
      "|GrandRapids        |338  |\n",
      "|SouthCarolina      |338  |\n",
      "|TotalUS            |338  |\n",
      "|WestTexNewMexico   |335  |\n",
      "|Louisville         |338  |\n",
      "|Philadelphia       |338  |\n",
      "|Sacramento         |338  |\n",
      "|DallasFtWorth      |338  |\n",
      "|Indianapolis       |338  |\n",
      "|LasVegas           |338  |\n",
      "|Nashville          |338  |\n",
      "|GreatLakes         |338  |\n",
      "|Detroit            |338  |\n",
      "|Albany             |338  |\n",
      "|Portland           |338  |\n",
      "|CincinnatiDayton   |338  |\n",
      "|SanDiego           |338  |\n",
      "|Boise              |338  |\n",
      "|HarrisburgScranton |338  |\n",
      "|StLouis            |338  |\n",
      "|NewOrleansMobile   |338  |\n",
      "|Columbus           |338  |\n",
      "|Pittsburgh         |338  |\n",
      "|MiamiFtLauderdale  |338  |\n",
      "|SouthCentral       |338  |\n",
      "|Chicago            |338  |\n",
      "|BuffaloRochester   |338  |\n",
      "|Tampa              |338  |\n",
      "|Southeast          |338  |\n",
      "|Plains             |338  |\n",
      "|Atlanta            |338  |\n",
      "|BaltimoreWashington|338  |\n",
      "|Seattle            |338  |\n",
      "|SanFrancisco       |338  |\n",
      "|HartfordSpringfield|338  |\n",
      "|Spokane            |338  |\n",
      "|NorthernNewEngland |338  |\n",
      "|Roanoke            |338  |\n",
      "|LosAngeles         |338  |\n",
      "|Houston            |338  |\n",
      "|Jacksonville       |338  |\n",
      "|RaleighGreensboro  |338  |\n",
      "|West               |338  |\n",
      "|NewYork            |338  |\n",
      "|Syracuse           |338  |\n",
      "|California         |338  |\n",
      "|Orlando            |338  |\n",
      "|Charlotte          |338  |\n",
      "|Midsouth           |338  |\n",
      "|Denver             |338  |\n",
      "|Boston             |338  |\n",
      "|Northeast          |338  |\n",
      "|RichmondNorfolk    |338  |\n",
      "+-------------------+-----+\n",
      "\n",
      "54\n"
     ]
    }
   ],
   "source": [
    "wordCountsDF = (df.select(\"region\")\n",
    "                .groupBy('region').count())\n",
    "wordCountsDF.show(df.count(), False)\n",
    "print((wordCountsDF).count())\n",
    "\n",
    "counts=df.map(lambda x:[(c,1)for c in x])\n",
    "for row in counts.collect():\n",
    "    print .parallelize(row).reduceByKey(lambda x,y:x+y).collect()\n",
    "\n",
    "\n",
    "wordsLengthsDF =data.select(length('region').alias('lengths'),\"region\")\n",
    "wordsLengthsDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----+\n",
      "|Name|Value|  id|\n",
      "+----+-----+----+\n",
      "|   A|    1|NULL|\n",
      "|   B|    3| 456|\n",
      "+----+-----+----+\n",
      "\n",
      "+----+-----+---+\n",
      "|Name|Value| id|\n",
      "+----+-----+---+\n",
      "|   B|    3|456|\n",
      "+----+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = spark.createDataFrame([ (\"A\", 1, None), (\"B\", None, \"123\" ), (\"B\", 3, \"456\"), (\"D\", None, None), ], [\"Name\", \"Value\", \"id\"]) \n",
    "\n",
    "df1 = df.na.drop(subset='Value')  \n",
    "df1.show()\n",
    "\n",
    "df2=df.na.drop(subset=[\"Value\",\"id\"])\n",
    "df2.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
